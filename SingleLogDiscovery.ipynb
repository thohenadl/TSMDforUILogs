{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Motif Discovery for User Interaction Logs\n",
    "\n",
    "### Description\n",
    "\n",
    "Time series data mining plays a crucial role in uncovering routines within user interaction logs. By analyzing sequences of user actions over time, data mining techniques can identify recurring patterns and behaviors. This allows us to understand how users typically navigate through a system, what actions they perform in sequence, and at what intervals. By uncovering these routines, we can gain valuable insights into user habits and preferences. This knowledge can then be used to optimize user interfaces, personalize experiences, and ultimately improve user satisfaction. For example, time series data mining might reveal a common sequence of actions users take to complete a specific task. This information could be used to streamline the process by suggesting the next step or automating repetitive actions.\n",
    "\n",
    "### Functionallity of this Notebook\n",
    "\n",
    "This notebook has three sections seperated into data preprocessing, Time Series Mining, and visualisation through Process Discovery.\n",
    "As with any Jupyter Notebook you can run each cell. For the method to properly work you have to setup the first cell after the library import accordingly. This cell contains the settings of the discovery approach. The attributes to be set are described in more detail before the cell.\n",
    "\n",
    "1. Section Preprocessing: In this section the necessery libraries are imported and the UI log is processed.\n",
    "2. Section Time Series Mining: The algorithm discovers the motifs based on the setup parameters.\n",
    "    - First, the UI log is encoded using our continuous hot encoding methodology.\n",
    "    - Second, if you set the parameter for window size calculation the window size will be calculated. Otherwise the specified window size is used.\n",
    "    - Third, the motif discovery is performed for the number of motifs you specified in the settings. \n",
    "3. The discovered motifs in the UI log are processed in a process discovery algorithm. The resulting directly follows graph is presented.\n",
    "\n",
    "#### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stumpy\n",
    "\n",
    "import util.util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pm4py\n",
    "import webbrowser\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings\n",
    "\n",
    "UiLogPath >>> String: Folder path in which the UI log is stored.\n",
    "\n",
    "UiLogFilename >>> String: Name of the UiLog.\n",
    "\n",
    "UiLogContextColumns >>> List: List of all names that should be considered as discovery dimensions. E.g., in Agostinelli et al.s logs we have considered the columns \"case:concept:name\", \"application\", and \"concept:name\". In the Activity Window Tracking by Beerepoot et al. we considered the columns \"Title\" and \"App\".\n",
    "\n",
    "TimeStampColumn >>> Str: Name of the column containing the time stamp in the UI log.\n",
    "\n",
    "WindowSizeCalculation >>> True or False: If True the window size will be calculated using the calculation method described in our paper based on the method in \n",
    "\n",
    "BreakTime >>> Int: Integer representing the number of seconds that are considered as a significant user break, e.g., lunch break or break between two UI log recording sessions. Set this parameter to exclude these breaks from the window size calculation. We recommend 300 seconds, i.e., 5 minutes, as an initial start value for breaks.\n",
    "\n",
    "ManualWindowSize >>> int: Set an integer value if the previous parameter is set to False. Otherwise a default value of 1% of the log length is choosen.\n",
    "\n",
    "NumberOfMotifsToDiscover >>> int: Integer value ranging from 2 to infinity (possibly) as input for the discovery of multiple occurances of the motif. The result will contain the number of motifs with the closest matching distance measure independent of actual motif similiarity.\n",
    "\n",
    "The settings are initially set for the UI log from our running example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Select One of the following or set own parameters to own UI log ----\n",
    "UiLogPath = \"logs/smartRPA/percentageComparison/\"\n",
    "UiLogFilename = \"LenLogLong_1_0_1_10_10_0.001_10000000.csv\"\n",
    "encoding_method = \"utf-8\"\n",
    "seperator = \",\"\n",
    "awt_data = False\n",
    "\n",
    "# UiLogPath = \"logs/Banking/\"\n",
    "# UiLogFilename = \"TSMD Log Sparkass_combined.csv\"\n",
    "# encoding_method = \"utf-8\"\n",
    "# seperator = \",\"\n",
    "# awt_data = False\n",
    "\n",
    "# UiLogPath = \"logs/AWT/\"\n",
    "# UiLogFilename = \"AWT_data_Iris_March_2023_labelled.csv\"\n",
    "# encoding_method  = \"latin-1\"\n",
    "# seperator = \";\"\n",
    "# awt_data = True\n",
    "\n",
    "# ---- Configure your settings according to the approach ----\n",
    "ContextColumns = [\"category\",\"application\",\"concept:name\"]\n",
    "timeStampColumn = \"time:timestamp\"\n",
    "WindowSizeCalculation = False\n",
    "BreakTime = 300\n",
    "ManualWindowSize = 10\n",
    "NumberOfMotifsToDiscover = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomho\\AppData\\Local\\Temp\\ipykernel_15400\\2158939382.py:4: DtypeWarning: Columns (23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file = pd.read_csv(UiLogPath + UiLogFilename, encoding=encoding_method, sep=seperator)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 229. MiB for an array with shape (3, 10000000) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ---- Do not change from here; Execute Only ----\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ---- PreProcessing ----\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUiLogPath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mUiLogFilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseperator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m uiLog \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mencoding_UiLog(file,orderedColumnsList\u001b[38;5;241m=\u001b[39mContextColumns,hierarchy_based\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,cooccuranceBased\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m WindowSizeCalculation:\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1765\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1762\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1763\u001b[0m         new_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index)\n\u001b[1;32m-> 1765\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2086\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2069\u001b[0m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2070\u001b[0m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2082\u001b[0m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2083\u001b[0m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2085\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2086\u001b[0m         blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_form_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2087\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2088\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2160\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[0;32m   2157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mtype, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m   2158\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m-> 2160\u001b[0m values, placement \u001b[38;5;241m=\u001b[39m \u001b[43m_stack_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtup_block\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2162\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2200\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2197\u001b[0m first \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2198\u001b[0m shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(arrays),) \u001b[38;5;241m+\u001b[39m first\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m-> 2200\u001b[0m stacked \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m   2202\u001b[0m     stacked[i] \u001b[38;5;241m=\u001b[39m arr\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 229. MiB for an array with shape (3, 10000000) and data type object"
     ]
    }
   ],
   "source": [
    "# ---- Do not change from here; Execute Only ----\n",
    "\n",
    "# ---- PreProcessing ----\n",
    "file = pd.read_csv(UiLogPath + UiLogFilename, encoding=encoding_method, sep=seperator)\n",
    "uiLog = util.util.encoding_UiLog(file,orderedColumnsList=ContextColumns,hierarchy_based=True,cooccuranceBased=False)\n",
    "if WindowSizeCalculation:\n",
    "    percentil = 100\n",
    "    quartile, quartile_indices, average_elements = util.util.windowSizeByBreak(file, timeStampColumn, BreakTime, percentil)\n",
    "    if average_elements is not None:\n",
    "        size = average_elements\n",
    "        print(f\"Average number of elements between breaks occurrences: {average_elements:.2f}\")\n",
    "    else:\n",
    "        size = len(file)*0.01\n",
    "        print(f\"Not enough data to calculate the window size. Size will be one percent of log length: {len(file)*0.01}\")\n",
    "    \n",
    "else:\n",
    "    size = ManualWindowSize\n",
    "    print(f\"The window size was manually set and is {size}.\")\n",
    "\n",
    "# ---- Time Series Mining ----\n",
    "tm_matrix, event_series = util.util.discover_motifs(uiLog, size)\n",
    "top_motifs = stumpy.motifs(T=event_series, P=tm_matrix[:,0], min_neighbors=1, max_matches=NumberOfMotifsToDiscover)\n",
    "print(f\"The motif discovery is complete. The following indexes are the starting points of the discovered motifs: {np.sort(top_motifs[1][0])}\")\n",
    "caseuiLog = util.util.reduceLogToDiscovered(file,top_motifs[1][0],size)\n",
    "\n",
    "# ---- Process Discovery ----\n",
    "# Info: Does not work for AWT data as it does not have an action (concept:name) column\n",
    "if awt_data == False:\n",
    "    pm4pyDf = pm4py.format_dataframe(caseuiLog)\n",
    "    uiLogg, start_activities, end_activities = pm4py.discover_dfg(pm4pyDf)\n",
    "    pm4py.view_dfg(uiLogg, start_activities, end_activities)\n",
    "\n",
    "\n",
    "# ---- Motif Visualisation ----\n",
    "starting_row = 0\n",
    "ending_row = len(uiLog)-1\n",
    "ids = uiLog.loc[starting_row:ending_row,'tuple:id'].tolist()\n",
    "rows = [i for i in range(len(uiLog.loc[starting_row:ending_row,'tuple:id']))]\n",
    "\n",
    "#Plot Event data\n",
    "fig2, axs2 = plt.subplots(3, sharex=True, gridspec_kw={'hspace': 0})\n",
    "plt.suptitle('Motif (Pattern) Discovery', fontsize='10')\n",
    "\n",
    "axs2[0].scatter(rows, ids, alpha=0.8)\n",
    "axs2[0].set_ylabel('Events', fontsize='10')\n",
    "# Plot Timeseries data\n",
    "axs2[1].plot(event_series)\n",
    "axs2[1].set_ylabel('Timeseries', fontsize='10')\n",
    "# Plot Matrix profiles\n",
    "axs2[2].set_xlabel('Time', fontsize ='10')\n",
    "axs2[2].set_ylabel('Matrix Profile', fontsize='10')\n",
    "axs2[2].set_ylim(top=tm_matrix[:, 0].max()*1.1) #displaying the max value with some uplift for space in Graph\n",
    "axs2[2].plot(tm_matrix[:, 0])\n",
    "# Adding Dashed lines\n",
    "for discovered in top_motifs[1][0]:\n",
    "    axs2[0].axvline(x=discovered, linestyle=\"dashed\",color='C1')\n",
    "    axs2[1].axvline(x=discovered, linestyle=\"dashed\",color='C1')\n",
    "    axs2[2].axvline(x=discovered, linestyle=\"dashed\",color='C1')\n",
    "\n",
    "# Display Pattern overlay\n",
    "fig, ax = plt.subplots(figsize=(6.5, 2))\n",
    "plt.title('Motif Overlay', fontsize='10')\n",
    "ax.set_xlabel(\"Events\", fontsize='10')\n",
    "ax.set_ylabel(\"Timeseries\", fontsize='10')\n",
    "# Plot motif and nearest neighbor window\n",
    "for i, val in enumerate(top_motifs[1][0]):\n",
    "    colorPlot = 'C' + str(i)\n",
    "    ax.plot(event_series[val:val+size], color=colorPlot, label=f\"Motif {i}\")\n",
    "    \n",
    "plt.legend(loc=\"best\",fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# ---- Show reduced dataframe with cases in nice html display ----\n",
    "url = UiLogPath + 'discoveredUILog.html'\n",
    "caseuiLog.to_html(url)\n",
    "webbrowser.open('file://' + os.path.realpath(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeSeriesData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
