{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "import ast\n",
    "\n",
    "import util.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation SmartRPA > Action Logger\n",
    "\n",
    "Both tools use different attribute names and they require a transformation.\n",
    "Our baseline are SmartRPA logs. The following cell in this notebook takes as an input a SmartRPA file and gernerates an Action Logger file.\n",
    "Please Note: Some attributes in Action Logger exist that are not present in SmartRPA and vise versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomho\\AppData\\Local\\Temp\\ipykernel_20808\\2586912780.py:28: DtypeWarning: Columns (11,23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\tomho\\AppData\\Local\\Temp\\ipykernel_20808\\2586912780.py:28: DtypeWarning: Columns (23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\tomho\\AppData\\Local\\Temp\\ipykernel_20808\\2586912780.py:28: DtypeWarning: Columns (11,23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\tomho\\AppData\\Local\\Temp\\ipykernel_20808\\2586912780.py:28: DtypeWarning: Columns (23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para sustituir nombres de columnas\n",
    "column_mapping = {\n",
    "    \"case:concept:name\": \"caseID\",\n",
    "    \"category\": \"target.class\",\n",
    "    \"application\": \"targetApp\",\n",
    "    \"time:timestamp\": \"timeStamp\",\n",
    "    \"org:resource\": \"userID\",\n",
    "    \"concept:name\": \"eventType\",\n",
    "    \"browser_url\": \"url\",\n",
    "    \"clipboard_content\": \"content\",\n",
    "    \"workbook\": \"target.workbookName\",\n",
    "    \"tag_name\": \"target.tagName\",\n",
    "    \"tag_type\": \"target.type\",\n",
    "    \"tag_value\": \"target.value\",\n",
    "    \"tag_innerText\": \"target.innerText\",\n",
    "    \"tag_checked\": \"target.checked\",\n",
    "    \"tag_href\": \"target.href\",\n",
    "    \"tag_option\": \"target.option\",\n",
    "    \"tag_title\": \"target.title\",\n",
    "    \"id\": \"target.id\",\n",
    "    \"case:concept:name\": \"target.name\",\n",
    "    \"current_worksheet\": \"target.sheetName\",\n",
    "    \"tag_html\": \"target.innerHTML\"\n",
    "}\n",
    "\n",
    "def process_csv(file_path, results_path):\n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Renombrar columnas seg√∫n el diccionario\n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "    \n",
    "    # Convertir todos los valores a strings con quotes\n",
    "    # df = df.map(lambda x: f'{x}' if pd.notnull(x) else '')\n",
    "    \n",
    "    # Guardar el archivo CSV procesado\n",
    "    output_file = f\"processed_{os.path.basename(file_path)}\"\n",
    "    output_file = os.path.join(results_path, output_file)\n",
    "    df.to_csv(output_file, index=False, quoting=csv.QUOTE_ALL, na_rep='')\n",
    "    \n",
    "    # with open(file_path, 'r', newline='') as infile, open(new_file_path, 'w', newline='') as outfile:\n",
    "    #     reader = csv.reader(infile)\n",
    "    #     writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)\n",
    "    #     for row in reader:\n",
    "    #         writer.writerow(row)\n",
    "\n",
    "def process_directory(directory):\n",
    "    # Comprobar si en \"directory\" existe el directorio \"processed\", sino crearlo\n",
    "    processed_directory = os.path.join(directory, \"processed\")\n",
    "    if not os.path.exists(processed_directory):\n",
    "        os.makedirs(processed_directory)\n",
    "    \n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            try:\n",
    "                process_csv(file_path, processed_directory)\n",
    "            except:\n",
    "                print(f\"{file_name} could not be transformed.\")\n",
    "\n",
    "# Especifica la carpeta que deseas procesar\n",
    "directory_path = \"logs/smartRPA/percentageComparison/LenoComparison/\"\n",
    "\n",
    "process_directory(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Grund Truth Files 4 RPM Segmentor and n-grams for SmartRPA Segmentor\n",
    "\n",
    "SmartRPA does not require ground truth. Action Logger by Leno does. This part of the project is to create a ground truth txt file. With that file the common measures (precision, recall, and f1-score) can be calculated properly.\n",
    "\n",
    "Two options can be used here:\n",
    "\n",
    "1. Grund Truth Files for Leno et als. Approach: Adjust the activity pattern to the following:\n",
    "<blockquote>\n",
    "pattern = \"\"\n",
    "\n",
    "for _, row in log.iloc[indexes[0]:indexes[0] + motifLength].iterrows(): \n",
    "\n",
    "    activityPattern = f\"{row['concept:name']}_{row['application']}_{row['category']}\"\n",
    "\n",
    "    pattern = pattern + activityPattern.replace(\" \",\"\") + \" -1 \"\n",
    "\n",
    "\\# concat into string\n",
    "\n",
    "pattern_complete = pattern_complete + pattern + \" -2 \\n\"\n",
    " </blockquote>    \n",
    "\n",
    "The three attributes are concatenated by a \"_\" and all white spaces are removed.\n",
    "After each activity there is a \"-1\" added as this is required by the \"CloFast\" algorithm.\n",
    "All lines have to end with a \"-2\" as this is the CloFast line delimitor.\n",
    "\n",
    "2. N-Gram Patterns for Agostinelli et als. Approach: Adjust the code as follows, as only the action attribute is required\n",
    "<blockquote>\n",
    "pattern = \"\"\n",
    "\n",
    "for _, row in log.iloc[indexes[0]:indexes[0] + motifLength].iterrows():\n",
    "\n",
    "        activityPattern = f\"{row['concept:name']}\"\n",
    "\n",
    "        pattern = pattern + activityPattern.replace(\" \",\"\") + \" \"\n",
    "\n",
    "\\# concat into string\n",
    "\n",
    "pattern_complete = pattern_complete + pattern + \"\\n\"\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LenLog_1_10_1_10_25_5_5000.csv\n",
      "Final Mapping: {419114129000000: [4957, 4875, 3805, 3464, 2733, 2457, 2219, 1644, 1244, 1060]}\n",
      "unmutedTab clickRadioButton unmutedTab clickRadioButton unmutedTab uninstallBrowserExtension dragElement clickCheckboxButton uninstallBrowserExtension installBrowserExtension clickRadioButton uninstallBrowserExtension installBrowserExtension unmutedTab clickCheckboxButton unmutedTab uninstallBrowserExtension uninstallBrowserExtension clickRadioButton unmutedTab clickCheckboxButton clickRadioButton clickRadioButton clickCheckboxButton dragElement \n",
      "\n",
      "unmutedTab clickRadioButton unmutedTab clickRadioButton unmutedTab uninstallBrowserExtension dragElement clickCheckboxButton uninstallBrowserExtension installBrowserExtension clickRadioButton uninstallBrowserExtension installBrowserExtension unmutedTab clickCheckboxButton unmutedTab uninstallBrowserExtension uninstallBrowserExtension clickRadioButton unmutedTab clickCheckboxButton clickRadioButton clickRadioButton clickCheckboxButton dragElement \n",
      "\n",
      "LenLog_1_10_1_10_5_10_500.csv\n",
      "Final Mapping: {315052512000000: [492, 439, 395, 383, 210, 201, 175, 148, 141, 33]}\n",
      "dragElement submit moved slideshowEnd Unmount \n",
      "\n",
      "dragElement submit moved slideshowEnd Unmount \n",
      "\n",
      "LenLog_1_10_1_10_5_1_5000.csv\n",
      "Final Mapping: {119115909000000: [4227, 3551, 3435, 2756, 2743, 2654, 2629, 2133, 1947, 1250]}\n",
      "modified Unmount modified modified Unmount \n",
      "\n",
      "modified Unmount modified modified Unmount \n",
      "\n",
      "LenLog_1_10_1_20_25_10_5000.csv\n",
      "Final Mapping: {930082438000000: [4868, 4282, 4024, 3821, 3784, 3576, 3354, 3197, 3149, 2483, 2175, 2030, 1886, 1672, 1625, 1468, 1280, 878, 801, 690]}\n",
      "insertUSB insertUSB cut modified openFolder copy cut hotkey moved modified openFile openFile openFolder modified openFolder modified cut cut copy modified modified insertUSB openFolder openFolder modified \n",
      "\n",
      "insertUSB insertUSB cut modified openFolder copy cut hotkey moved modified openFile openFile openFolder modified openFolder modified cut cut copy modified modified insertUSB openFolder openFolder modified \n",
      "\n",
      "LenLog_1_10_1_20_25_1_50000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomho\\AppData\\Local\\Temp\\ipykernel_3228\\3016370305.py:17: DtypeWarning: Columns (11,23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  log = pd.read_csv(folder_path + log_filename, encoding=encoding_method, sep=seperator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mapping: {303174429000000: [48492, 47343, 45303, 45226, 38452, 37803, 36114, 36003, 34701, 27729, 25530, 23317, 20747, 20311, 19618, 15195, 9891, 9024, 7037, 6914]}\n",
      "clickLink clickLink clickLink uninstallBrowserExtension uninstallBrowserExtension unmutedTab installBrowserExtension clickCheckboxButton uninstallBrowserExtension dragElement clickRadioButton clickCheckboxButton installBrowserExtension dragElement uninstallBrowserExtension dragElement clickLink installBrowserExtension installBrowserExtension installBrowserExtension unmutedTab unmutedTab uninstallBrowserExtension uninstallBrowserExtension installBrowserExtension \n",
      "\n",
      "clickLink clickLink clickLink uninstallBrowserExtension uninstallBrowserExtension unmutedTab installBrowserExtension clickCheckboxButton uninstallBrowserExtension dragElement clickRadioButton clickCheckboxButton installBrowserExtension dragElement uninstallBrowserExtension dragElement clickLink installBrowserExtension installBrowserExtension installBrowserExtension unmutedTab unmutedTab uninstallBrowserExtension uninstallBrowserExtension installBrowserExtension \n",
      "\n",
      "LenLog_1_10_1_60_25_1_150000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomho\\AppData\\Local\\Temp\\ipykernel_3228\\3016370305.py:17: DtypeWarning: Columns (23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  log = pd.read_csv(folder_path + log_filename, encoding=encoding_method, sep=seperator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mapping: {917185036000000: [144344, 141494, 140280, 139838, 138227, 137490, 134871, 126101, 125687, 124599, 123525, 122636, 118149, 109252, 109090, 108864, 108608, 104147, 103544, 103278, 99850, 99422, 97166, 94753, 94401, 93252, 92955, 91620, 89169, 88011, 85172, 84106, 83772, 83352, 83293, 74722, 72651, 66730, 65238, 64470, 62100, 54310, 53859, 53578, 50782, 39627, 39458, 34801, 32472, 31794, 28819, 21654, 18204, 15366, 12093, 10208, 8178, 7372, 1768, 192]}\n",
      "printSubmitted Mount printSubmitted Mount printSubmitted printSubmitted programClose modified programClose printSubmitted programClose Mount modified Mount programClose programClose modified printSubmitted printSubmitted clickLink closeTab printSubmitted audibleTab closeWindow closeTab \n",
      "\n",
      "printSubmitted Mount printSubmitted Mount printSubmitted printSubmitted programClose modified programClose printSubmitted programClose Mount modified Mount programClose programClose modified printSubmitted printSubmitted clickLink closeTab printSubmitted audibleTab closeWindow closeTab \n",
      "\n",
      "LenLog_1_1_10_25_5_5000.csv\n",
      "Final Mapping: {1010215011000000: [4420, 4104, 2263, 1932, 1904, 1397, 775, 712, 644, 499]}\n",
      "created openFile programOpen created selectFile selectFile created paste selectFile openFile printSubmitted selectFile cut paste openFile openFile cut paste created openFile detachTab closeTab installBrowserExtension closeTab closeTab \n",
      "\n",
      "created openFile programOpen created selectFile selectFile created paste selectFile openFile printSubmitted selectFile cut paste openFile openFile cut paste created openFile detachTab closeTab installBrowserExtension closeTab closeTab \n",
      "\n",
      "LenLog_1_1_10_5_10_500.csv\n",
      "Final Mapping: {1028102022000000: [493, 460, 428, 366, 307, 292, 282, 264, 233, 104]}\n",
      "form_submit newBookmark changeField submit newTab \n",
      "\n",
      "form_submit newBookmark changeField submit newTab \n",
      "\n",
      "LenLog_1_1_10_5_1_5000.csv\n",
      "Final Mapping: {110014419000000: [4282, 4239, 3774, 3612, 2094, 1974, 1563, 1312, 516, 238]}\n",
      "paste paste printSubmitted Unmount created \n",
      "\n",
      "paste paste printSubmitted Unmount created \n",
      "\n",
      "LenLog_1_1_20_25_10_5000.csv\n",
      "Final Mapping: {205104250000000: [4645, 4576, 4241, 3525, 3446, 3219, 3057, 3011, 2703, 2440, 2368, 1842, 1319, 1168, 1032, 914, 819, 614, 485, 206]}\n",
      "clickRadioButton installBrowserExtension clickRadioButton clickLink clickLink installBrowserExtension clickLink clickLink clickLink uninstallBrowserExtension uninstallBrowserExtension installBrowserExtension clickRadioButton installBrowserExtension clickCheckboxButton clickLink clickCheckboxButton dragElement installBrowserExtension installBrowserExtension unmutedTab installBrowserExtension dragElement clickLink installBrowserExtension \n",
      "\n",
      "clickRadioButton installBrowserExtension clickRadioButton clickLink clickLink installBrowserExtension clickLink clickLink clickLink uninstallBrowserExtension uninstallBrowserExtension installBrowserExtension clickRadioButton installBrowserExtension clickCheckboxButton clickLink clickCheckboxButton dragElement installBrowserExtension installBrowserExtension unmutedTab installBrowserExtension dragElement clickLink installBrowserExtension \n",
      "\n",
      "LenLog_1_1_20_25_1_50000.csv\n",
      "Final Mapping: {701054121000000: [49314, 42141, 41497, 39402, 38180, 34300, 33925, 32296, 30993, 27939, 27145, 26317, 21192, 20528, 20384, 19742, 6699, 4998, 3618, 3421]}\n",
      "unmutedTab uninstallBrowserExtension clickRadioButton installBrowserExtension clickCheckboxButton unmutedTab installBrowserExtension unmutedTab unmutedTab uninstallBrowserExtension uninstallBrowserExtension dragElement installBrowserExtension dragElement uninstallBrowserExtension clickCheckboxButton uninstallBrowserExtension dragElement clickRadioButton installBrowserExtension clickLink clickRadioButton unmutedTab clickRadioButton uninstallBrowserExtension \n",
      "\n",
      "unmutedTab uninstallBrowserExtension clickRadioButton installBrowserExtension clickCheckboxButton unmutedTab installBrowserExtension unmutedTab unmutedTab uninstallBrowserExtension uninstallBrowserExtension dragElement installBrowserExtension dragElement uninstallBrowserExtension clickCheckboxButton uninstallBrowserExtension dragElement clickRadioButton installBrowserExtension clickLink clickRadioButton unmutedTab clickRadioButton uninstallBrowserExtension \n",
      "\n",
      "LenLog_1_1_60_25_1_150000.csv\n",
      "Final Mapping: {418114646000000: [148800, 147195, 145854, 141172, 140790, 136901, 135575, 132733, 132604, 132305, 131737, 131176, 127013, 123700, 121880, 121528, 117346, 110760, 108201, 101586, 95311, 93702, 92338, 88592, 86191, 83906, 79096, 72769, 68631, 68604, 66610, 66111, 54179, 54085, 50115, 46456, 44613, 44077, 43531, 43005, 42153, 38065, 37592, 37205, 31428, 31098, 28177, 27542, 26475, 26175, 22604, 21662, 19442, 14623, 13268, 9082, 8052, 5398, 3752, 1956]}\n",
      "dragElement unmutedTab installBrowserExtension installBrowserExtension clickRadioButton dragElement clickRadioButton dragElement unmutedTab dragElement clickRadioButton clickLink clickRadioButton clickLink unmutedTab clickRadioButton installBrowserExtension uninstallBrowserExtension unmutedTab dragElement clickLink clickCheckboxButton clickRadioButton clickLink unmutedTab \n",
      "\n",
      "dragElement unmutedTab installBrowserExtension installBrowserExtension clickRadioButton dragElement clickRadioButton dragElement unmutedTab dragElement clickRadioButton clickLink clickRadioButton clickLink unmutedTab clickRadioButton installBrowserExtension uninstallBrowserExtension unmutedTab dragElement clickLink clickCheckboxButton clickRadioButton clickLink unmutedTab \n",
      "\n",
      "LenLog_1_20_1_10_25_5_5000.csv\n",
      "Final Mapping: {306062233000000: [4992, 4824, 4527, 3502, 2088, 1611, 1503, 1240, 314, 189]}\n",
      "uninstallBrowserExtension selectFolder moveTab Unmount navigateTo printSubmitted newBookmark submit clickCheckboxButton clickCheckboxButton form_submit moveTab enableBrowserExtension programOpen selectFile created created copy newBookmark selectFolder selectFolder navigateTo cut selectFolder deleted \n",
      "\n",
      "uninstallBrowserExtension selectFolder moveTab Unmount navigateTo printSubmitted newBookmark submit clickCheckboxButton clickCheckboxButton form_submit moveTab enableBrowserExtension programOpen selectFile created created copy newBookmark selectFolder selectFolder navigateTo cut selectFolder deleted \n",
      "\n",
      "LenLog_1_20_1_10_5_10_500.csv\n",
      "Final Mapping: {611001654000000: [423, 402, 354, 326, 248, 180, 70, 44, 17, 10]}\n",
      "addinUninstalledWorkbook openDocument doubleClickWindow slideshowBegin activateWorkbook \n",
      "\n",
      "addinUninstalledWorkbook openDocument doubleClickWindow slideshowBegin activateWorkbook \n",
      "\n",
      "LenLog_1_20_1_10_5_1_5000.csv\n",
      "Final Mapping: {909152005000000: [4540, 4288, 3887, 3785, 3647, 3383, 2858, 2234, 278, 225]}\n",
      "Mount programClose Mount printSubmitted printSubmitted \n",
      "\n",
      "Mount programClose Mount printSubmitted printSubmitted \n",
      "\n",
      "LenLog_1_20_1_20_25_10_5000.csv\n",
      "Final Mapping: {727114948000000: [5335, 5307, 4713, 4641, 3559, 3522, 2919, 2616, 2327, 2114, 1919, 1878, 1731, 1361, 1130, 948, 337, 275, 107, 36]}\n",
      "uninstallBrowserExtension clickRadioButton installBrowserExtension clickLink clickCheckboxButton dragElement installBrowserExtension installBrowserExtension clickRadioButton uninstallBrowserExtension dragElement uninstallBrowserExtension clickLink unmutedTab uninstallBrowserExtension clickCheckboxButton installBrowserExtension clickLink clickLink uninstallBrowserExtension dragElement clickLink unmutedTab unmutedTab clickCheckboxButton \n",
      "\n",
      "uninstallBrowserExtension clickRadioButton installBrowserExtension clickLink clickCheckboxButton dragElement installBrowserExtension installBrowserExtension clickRadioButton uninstallBrowserExtension dragElement uninstallBrowserExtension clickLink unmutedTab uninstallBrowserExtension clickCheckboxButton installBrowserExtension clickLink clickLink uninstallBrowserExtension dragElement clickLink unmutedTab unmutedTab clickCheckboxButton \n",
      "\n",
      "LenLog_1_20_1_20_25_1_50000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomho\\AppData\\Local\\Temp\\ipykernel_3228\\3016370305.py:17: DtypeWarning: Columns (11,23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  log = pd.read_csv(folder_path + log_filename, encoding=encoding_method, sep=seperator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mapping: {621013550000000: [49229, 46018, 45309, 41532, 34501, 34305, 32673, 30750, 30272, 28517, 26948, 26372, 25886, 24528, 23938, 21385, 20890, 18588, 14352, 1097]}\n",
      "modified modified programClose modified Mount printSubmitted Mount Mount programClose printSubmitted programClose Mount printSubmitted programClose Mount programClose programClose programClose programClose closeTab clickLink clickLink cancelDialog submit Mount \n",
      "\n",
      "modified modified programClose modified Mount printSubmitted Mount Mount programClose printSubmitted programClose Mount printSubmitted programClose Mount programClose programClose programClose programClose closeTab clickLink clickLink cancelDialog submit Mount \n",
      "\n",
      "LenLog_1_20_1_60_25_1_150000.csv\n",
      "Final Mapping: {226073151000000: [150231, 149153, 145314, 141291, 140289, 138216, 137801, 133709, 131996, 129973, 126454, 126044, 124353, 121968, 112681, 112156, 111429, 110138, 104146, 100460, 96682, 96106, 94998, 94534, 93191, 91911, 89394, 84154, 76882, 76678, 74689, 74576, 74091, 69343, 67303, 64036, 63119, 62148, 60292, 59845, 57465, 57318, 55809, 51100, 48943, 48568, 46498, 41652, 33675, 30728, 29989, 28915, 28392, 25914, 24212, 17829, 16690, 12355, 4867, 83]}\n",
      "form_submit attachTab unpinnedTab closeTab unpinnedTab newBookmark reload selectFolder moveTab moveTab changeField insertUSB insertUSB printSubmitted deleted cut selectText programOpen selectFile Mount modified insertUSB newBookmark selectFolder Mount \n",
      "\n",
      "form_submit attachTab unpinnedTab closeTab unpinnedTab newBookmark reload selectFolder moveTab moveTab changeField insertUSB insertUSB printSubmitted deleted cut selectText programOpen selectFile Mount modified insertUSB newBookmark selectFolder Mount \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomho\\AppData\\Local\\Temp\\ipykernel_3228\\3016370305.py:17: DtypeWarning: Columns (23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  log = pd.read_csv(folder_path + log_filename, encoding=encoding_method, sep=seperator)\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "\n",
    "# Folder path in which the UI logs are which should be transformed into RPM Segmentor ground truth or SmartRPA segmentor files\n",
    "folder_path = \"logs/smartRPA/percentageComparison/\"\n",
    "# File in which the information about the motif indexes is located. Generated by the \"validationLogCreation.ipynb\"\n",
    "grundTruth_ValidationData_filename = \"validationDataPercentage.csv\"\n",
    "\n",
    "\n",
    "seperator = \",\" # \",\" for SmartRPA, \";\" for Tockler/AWT\n",
    "encoding_method = \"utf-8\" # UTF-8 for SmartRPA, latin-1 for Tockler/AWT\n",
    "\n",
    "# Read Files 1. Log 2. Validation Data to identify patterns\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.startswith(\"LenLog\") and file.endswith((\"_500.csv\", \"_5000.csv\", \"_50000.csv\", \"_150000.csv\")):\n",
    "        print(file)\n",
    "        log_filename = file\n",
    "        log = pd.read_csv(folder_path + log_filename, encoding=encoding_method, sep=seperator)\n",
    "        validation_data = pd.read_csv(folder_path + grundTruth_ValidationData_filename, encoding=encoding_method, sep=seperator)\n",
    "\n",
    "        # Get Index of Motifs\n",
    "\n",
    "        comparisonVariables = validation_data.loc[validation_data['uiLogName'] == log_filename]\n",
    "\n",
    "        motifLength = int(comparisonVariables[\"motifLength\"].iloc[0])\n",
    "\n",
    "        motifSpots = comparisonVariables[\"motifSpots\"]\n",
    "        motifSpots = util.util.extract_numbers(motifSpots[motifSpots.index[0]])\n",
    "        motifAtSpot = comparisonVariables[\"caseIds\"]\n",
    "        try:\n",
    "            motifAtSpot = util.util.extract_numbers(motifAtSpot[motifAtSpot.index[0]])\n",
    "        except:\n",
    "            all_integers = []\n",
    "            for item in motifAtSpot:\n",
    "                # Safely evaluate the string to convert it into a Python list\n",
    "                evaluated_list = ast.literal_eval(item)\n",
    "                all_integers.extend(evaluated_list)  # Flatten and collect integers\n",
    "            motifAtSpot = all_integers\n",
    "\n",
    "        # Get Dataframe range\n",
    "        motifsIndexMapping = util.util.get_indexes_for_identifiers(motifSpots,motifAtSpot)\n",
    "\n",
    "        print(f\"Final Mapping: {motifsIndexMapping}\")\n",
    "\n",
    "        # Generate Filename\n",
    "        grundTruth_File = log_filename.split(\".\")[0] + \".txt\"\n",
    "        pattern_complete = \"\"\n",
    "        for motif, indexes in motifsIndexMapping.items():\n",
    "            # Strip down attributes\n",
    "            pattern = \"\"\n",
    "\n",
    "            for _, row in log.iloc[indexes[0]:indexes[0] + motifLength].iterrows():\n",
    "\n",
    "                activityPattern = f\"{row['concept:name']}\"\n",
    "\n",
    "                pattern = pattern + activityPattern.replace(\" \",\"\") + \" \"\n",
    "\n",
    "            # concat into string\n",
    "\n",
    "            pattern_complete = pattern_complete + pattern + \"\\n\"\n",
    "        print(pattern_complete)\n",
    "\n",
    "        # Add to file\n",
    "        with open(folder_path + \"pattern-\" + grundTruth_File, 'w') as file:\n",
    "            print(pattern_complete)\n",
    "            file.write(pattern_complete + '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall, Precision, and F1-Score Calculation for SmartRPA Segmentor results\n",
    "\n",
    "This script part is used to calculate the Recall, Precision, and F1-Score based on two input files:\n",
    "\n",
    "1. The results of the Agostinelli et al. Segmentor named \"result_Agostinelli-[Log Name]\"\n",
    "2. The n-gram generated from the UI Log from the previous cell named \"pattern-[Log Name]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result File result_Agostinelli-LenLog_1_10_1_10_25_5_5000.txt\n",
      "Total longer routines discovered: 0\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1-score: 0\n",
      "Result File result_Agostinelli-LenLog_1_10_1_10_5_10_500.txt\n",
      "Total longer routines discovered: 0\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1-score: 0\n",
      "Result File result_Agostinelli-LenLog_1_10_1_10_5_1_5000.txt\n",
      "Total longer routines discovered: 0\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1-score: 0\n",
      "Result File result_Agostinelli-LenLog_1_10_1_20_25_10_5000.txt\n",
      "Total longer routines discovered: 0\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1-score: 0\n",
      "Result File result_Agostinelli-LenLog_1_1_10_25_5_5000.txt\n",
      "Total longer routines discovered: 0\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1-score: 0\n",
      "Result File result_Agostinelli-LenLog_1_1_10_5_10_500.txt\n",
      "Total longer routines discovered: 1\n",
      "Total True Positives: 1\n",
      "ro_motifs: 10\n",
      "Precision: 1.0\n",
      "Recall: 0.1\n",
      "F1-score: 0.18181818181818182\n",
      "Result File result_Agostinelli-LenLog_1_1_10_5_1_5000.txt\n",
      "Total longer routines discovered: 0\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1-score: 0\n",
      "Result File result_Agostinelli-LenLog_1_1_20_25_10_5000.txt\n",
      "Total longer routines discovered: 6\n",
      "Total True Positives: 6\n",
      "ro_motifs: 20\n",
      "Precision: 1.0\n",
      "Recall: 0.3\n",
      "F1-score: 0.4615384615384615\n",
      "Result File result_Agostinelli-LenLog_1_20_1_10_25_5_5000.txt\n",
      "Total longer routines discovered: 0\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1-score: 0\n",
      "Result File result_Agostinelli-LenLog_1_20_1_10_5_10_500.txt\n",
      "Total longer routines discovered: 0\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1-score: 0\n",
      "Result File result_Agostinelli-LenLog_1_20_1_10_5_1_5000.txt\n",
      "Total longer routines discovered: 0\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1-score: 0\n",
      "Result File result_Agostinelli-LenLog_1_20_1_20_25_10_5000.txt\n",
      "Total longer routines discovered: 0\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1-score: 0\n"
     ]
    }
   ],
   "source": [
    "# Settings - Folder Path in which the discovered n-gram txt files from Agostinelli et als method \n",
    "# and the results of the pervious cell (n-gram baseline) are stored\n",
    "folder_path = \"logs/smartRPA/percentageComparison/AgostinelliComparison_500_5000_50k-150k/\"\n",
    "\n",
    "def remove_trailing_number(line):\n",
    "    \"\"\"\n",
    "    Removes the number at the end of a string.\n",
    "\n",
    "    Parameters:\n",
    "    line (str): Input string.\n",
    "\n",
    "    Returns:\n",
    "    str: String with the trailing number removed.\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\d+$', '', line)\n",
    "\n",
    "def read_text_file_to_list(file_path):\n",
    "    \"\"\"\n",
    "    Reads a text file and stores each line as an element in a list.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The full path to the text file.\n",
    "\n",
    "    Returns:\n",
    "    list: A list where each element is a line from the text file.\n",
    "    \"\"\"\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"The file '{file_path}' does not exist.\")\n",
    "        return []\n",
    "\n",
    "    # Read the file and store each line in a list\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Remove trailing newline characters from each line\n",
    "    lines = [line.strip() for line in lines]\n",
    "    lines = [remove_trailing_number(line) for line in lines]\n",
    "\n",
    "    return lines\n",
    "\n",
    "def match_files(folder_path, type=1):\n",
    "    \"\"\"\n",
    "    Matches files starting with 'result_Agostinelli-' to their counterparts\n",
    "    starting with 'agostinelli_patternBaseline-' in the same folder.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): Path to the folder containing the files.\n",
    "    type (int: default 1): If the files have the pre-text (1) or just are same files with .txt (2)\n",
    "\n",
    "    Returns:\n",
    "    list: List of tuples with matched files (result_file, pattern_file).\n",
    "    \"\"\"\n",
    "    # Get all files in the folder\n",
    "    all_files = os.listdir(folder_path)\n",
    "\n",
    "    # Separate files by their prefixes\n",
    "    result_files = [f for f in all_files if f.startswith('result_Agostinelli-')]\n",
    "    pattern_files = [f for f in all_files if f.startswith('pattern-LenLog')]\n",
    "\n",
    "    # Match result files to pattern files\n",
    "    matches = []\n",
    "    for result_file in result_files:\n",
    "        # Extract the unique identifier from the result file\n",
    "        identifier = result_file.split('result_Agostinelli-', 1)[1]\n",
    "        identifier = identifier[:-5]\n",
    "        # Search for a corresponding pattern file\n",
    "        for pattern_file in pattern_files:\n",
    "            if identifier in pattern_file:\n",
    "                matches.append((result_file, pattern_file))\n",
    "                break\n",
    "\n",
    "    return matches\n",
    "\n",
    "def find_matching_subpatterns_with_summed_numbers(pattern_file, result_file):\n",
    "    \"\"\"\n",
    "    Checks if any patterns from the pattern file occur as sub-patterns in the result file\n",
    "    and sums the numbers from all matching lines for each pattern.\n",
    "\n",
    "    Parameters:\n",
    "    pattern_file (str): Path to the text file containing expected patterns.\n",
    "    result_file (str): Path to the text file containing result patterns.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are patterns from the pattern file, and values are:\n",
    "          - The sum of numbers from all matching lines in the result file.\n",
    "          - None if the pattern is not found.\n",
    "    \"\"\"\n",
    "    # Read the patterns from both files\n",
    "    with open(pattern_file, 'r') as pf:\n",
    "        patterns = [line.strip() for line in pf.readlines()]\n",
    "    \n",
    "    with open(result_file, 'r') as rf:\n",
    "        results = [line.strip() for line in rf.readlines()]\n",
    "\n",
    "    # Check for sub-patterns and sum numbers\n",
    "    pattern_matches = {}\n",
    "    for pattern in patterns:\n",
    "        total_sum = 0\n",
    "        for result in results:\n",
    "            if pattern in result:\n",
    "                # Extract the first number in the matching line\n",
    "                number_match = re.search(r'\\d+', result)\n",
    "                if number_match:\n",
    "                    total_sum += int(number_match.group())\n",
    "        # Store the total sum or None if no matches were found\n",
    "        pattern_matches[pattern] = total_sum if total_sum > 0 else None\n",
    "\n",
    "    return pattern_matches\n",
    "\n",
    "def sum_numbers_for_longer_patterns(result_file, pattern_word_length):\n",
    "    \"\"\"\n",
    "    Sums the numbers in result file lines with word counts greater than the specified pattern length.\n",
    "\n",
    "    Parameters:\n",
    "    pattern_file (str): Path to the text file containing expected patterns.\n",
    "    result_file (str): Path to the text file containing result patterns.\n",
    "    pattern_word_length (int): Minimum word count for patterns from the pattern file.\n",
    "\n",
    "    Returns:\n",
    "    int: The sum of numbers in result patterns that exceed the pattern word length.\n",
    "    \"\"\"\n",
    "    # Read the result file\n",
    "    with open(result_file, 'r') as rf:\n",
    "        results = [line.strip() for line in rf.readlines()]\n",
    "\n",
    "    # Sum the numbers for result patterns longer than the pattern word length\n",
    "    total_sum = 0\n",
    "    for result in results:\n",
    "        # Count words in the result line\n",
    "        word_count = len(result.split())\n",
    "        if word_count > pattern_word_length:\n",
    "            # Extract the first number in the result line\n",
    "            number_match = re.search(r'\\d+', result)\n",
    "            if number_match:\n",
    "                total_sum += int(number_match.group())\n",
    "\n",
    "    return total_sum\n",
    "\n",
    "matches = match_files(folder_path)\n",
    "\n",
    "result_df = pd.DataFrame(columns=[\"Filename\", \"n_motifs\", \"p\", \"r_o\",\"rlen\",\"precision\",\"recall\",\"f1score\"])\n",
    "for result, pattern in matches:\n",
    "    # print(f\"Result File: {result}, Matching Pattern File: {pattern}\")\n",
    "    file_path_result = os.path.join(folder_path, result)\n",
    "    lines_list_result = read_text_file_to_list(file_path_result)\n",
    "    # print(\"Contents of the text file as a list:\")\n",
    "    # print(lines_list)\n",
    "    file_path_pattern = os.path.join(folder_path, pattern)\n",
    "    lines_list_pattern = read_text_file_to_list(file_path_pattern)\n",
    "    # print(\"Contents of the text file as a list:\")\n",
    "    # print(lines_list_pattern)\n",
    "\n",
    "    patterns_found = find_matching_subpatterns_with_summed_numbers(file_path_pattern, file_path_result)\n",
    "    # Print the results\n",
    "    print(f\"Result File {result}\")\n",
    "    total_true_positives = 0\n",
    "    for found_pattern, occurred in patterns_found.items():\n",
    "        # Handle None as 0\n",
    "        value = occurred if occurred is not None else 0\n",
    "        total_true_positives += value\n",
    "        # print(f\"Pattern: '{pattern}' - Found as Sub-pattern: {value}\")\n",
    "\n",
    "\n",
    "    # Get number of activities (\"Words\") from filename\n",
    "    if \"rlen\" in result:\n",
    "        activities = result.split(\"rlen\")[1].split(\"_\")[0]\n",
    "        ro_motifs = result.split(\"ro\")[1].split(\"_\")[0]\n",
    "        p_overLog = result.split(\"_p\")[1].split(\"_\")[0]\n",
    "        n_motifs = result.split(\"_no\")[1].split(\"_\")[0]\n",
    "    else:\n",
    "        activities = result.split(\"_\")[5]\n",
    "        ro_motifs = result.split(\"_\")[4]\n",
    "        p_overLog = result.split(\"_\")[6]\n",
    "        n_motifs = result.split(\"_\")[2]\n",
    "    \n",
    "    total_discovered = sum_numbers_for_longer_patterns(file_path_result, int(activities))\n",
    "    print(f\"Total longer routines discovered: {total_discovered}\")\n",
    "    if total_discovered is None or total_true_positives == 0 or total_discovered == 0:\n",
    "        total_discovered = 0\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        print(f\"Total True Positives: {total_true_positives}\")\n",
    "        print(f\"ro_motifs: {ro_motifs}\")\n",
    "        precision = total_true_positives/total_discovered\n",
    "        recall = total_true_positives/int(ro_motifs)\n",
    "        if recall > 1:\n",
    "            recall = 1\n",
    "        f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1_score}\")\n",
    "    new_row = pd.DataFrame({\"Filename\": [pattern],\"n_motifs\": [n_motifs], \"p\": [p_overLog], \"r_o\": [ro_motifs],\"rlen\": [activities], \"precision\": [precision]\n",
    "                            ,\"recall\": [recall], \"f1score\": [f1_score]})\n",
    "    result_df = pd.concat([result_df, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>n_motifs</th>\n",
       "      <th>p</th>\n",
       "      <th>r_o</th>\n",
       "      <th>rlen</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pattern-LenLog_1_10_1_10_25_5_5000.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pattern-LenLog_1_10_1_10_5_10_500.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pattern-LenLog_1_10_1_10_5_1_5000.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pattern-LenLog_1_10_1_20_25_10_5000.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pattern-LenLog_1_1_10_25_5_5000.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pattern-LenLog_1_1_10_5_10_500.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pattern-LenLog_1_1_10_5_1_5000.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pattern-LenLog_1_1_20_25_10_5000.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pattern-LenLog_1_20_1_10_25_5_5000.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pattern-LenLog_1_20_1_10_5_10_500.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pattern-LenLog_1_20_1_10_5_1_5000.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pattern-LenLog_1_20_1_20_25_10_5000.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Filename n_motifs   p r_o rlen precision  \\\n",
       "0    pattern-LenLog_1_10_1_10_25_5_5000.txt        1  25   1   10         0   \n",
       "1     pattern-LenLog_1_10_1_10_5_10_500.txt        1   5   1   10         0   \n",
       "2     pattern-LenLog_1_10_1_10_5_1_5000.txt        1   5   1   10         0   \n",
       "3   pattern-LenLog_1_10_1_20_25_10_5000.txt        1  25   1   20         0   \n",
       "4       pattern-LenLog_1_1_10_25_5_5000.txt        1   5  10   25         0   \n",
       "5        pattern-LenLog_1_1_10_5_10_500.txt        1  10  10    5       1.0   \n",
       "6        pattern-LenLog_1_1_10_5_1_5000.txt        1   1  10    5         0   \n",
       "7      pattern-LenLog_1_1_20_25_10_5000.txt        1  10  20   25       1.0   \n",
       "8    pattern-LenLog_1_20_1_10_25_5_5000.txt        1  25   1   10         0   \n",
       "9     pattern-LenLog_1_20_1_10_5_10_500.txt        1   5   1   10         0   \n",
       "10    pattern-LenLog_1_20_1_10_5_1_5000.txt        1   5   1   10         0   \n",
       "11  pattern-LenLog_1_20_1_20_25_10_5000.txt        1  25   1   20         0   \n",
       "\n",
       "   recall   f1score  \n",
       "0       0         0  \n",
       "1       0         0  \n",
       "2       0         0  \n",
       "3       0         0  \n",
       "4       0         0  \n",
       "5     0.1  0.181818  \n",
       "6       0         0  \n",
       "7     0.3  0.461538  \n",
       "8       0         0  \n",
       "9       0         0  \n",
       "10      0         0  \n",
       "11      0         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Results from Agostinelli Patterns Excel File\n",
    "\n",
    "CSV File that contained all discovered results per file in just one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LenLog_1_10_1_20_25_10_5000\n",
      "\n",
      "LenLog_1_1_20_25_10_5000\n",
      "copy clickLink paste SlideSelectionChanged newPresentationSlide openDocument clickRadioButton installBrowserExtension clickRadioButton clickLink clickLink installBrowserExtension clickLink clickLink clickLink uninstallBrowserExtension uninstallBrowserExtension installBrowserExtension clickRadioButton installBrowserExtension clickCheckboxButton clickLink clickCheckboxButton dragElement installBrowserExtension installBrowserExtension unmutedTab installBrowserExtension dragElement clickLink installBrowserExtension 6.0\n",
      " newWindow copy clickLink paste SlideSelectionChanged newPresentationSlide openDocument clickRadioButton installBrowserExtension clickRadioButton clickLink clickLink installBrowserExtension clickLink clickLink clickLink uninstallBrowserExtension uninstallBrowserExtension installBrowserExtension clickRadioButton installBrowserExtension clickCheckboxButton clickLink clickCheckboxButton dragElement installBrowserExtension installBrowserExtension unmutedTab installBrowserExtension dragElement clickLink installBrowserExtension 7.0\n",
      " copy copy clickLink paste SlideSelectionChanged newPresentationSlide openDocument clickRadioButton installBrowserExtension clickRadioButton clickLink clickLink installBrowserExtension clickLink clickLink clickLink uninstallBrowserExtension uninstallBrowserExtension installBrowserExtension clickRadioButton installBrowserExtension clickCheckboxButton clickLink clickCheckboxButton dragElement installBrowserExtension installBrowserExtension unmutedTab installBrowserExtension dragElement clickLink installBrowserExtension 7.0\n",
      " paste copy clickLink paste SlideSelectionChanged newPresentationSlide openDocument clickRadioButton installBrowserExtension clickRadioButton clickLink clickLink installBrowserExtension clickLink clickLink clickLink uninstallBrowserExtension uninstallBrowserExtension installBrowserExtension clickRadioButton installBrowserExtension clickCheckboxButton clickLink clickCheckboxButton dragElement installBrowserExtension installBrowserExtension unmutedTab installBrowserExtension dragElement clickLink installBrowserExtension 7.0\n",
      " programClose moved copy clickLink paste SlideSelectionChanged newPresentationSlide openDocument clickRadioButton installBrowserExtension clickRadioButton clickLink clickLink installBrowserExtension clickLink clickLink clickLink uninstallBrowserExtension uninstallBrowserExtension installBrowserExtension clickRadioButton installBrowserExtension clickCheckboxButton clickLink clickCheckboxButton dragElement installBrowserExtension installBrowserExtension unmutedTab installBrowserExtension dragElement clickLink installBrowserExtension 8.0\n",
      " copy clickLink paste SlideSelectionChanged newPresentationSlide openDocument clickRadioButton installBrowserExtension clickRadioButton clickLink clickLink installBrowserExtension clickLink clickLink clickLink uninstallBrowserExtension uninstallBrowserExtension installBrowserExtension clickRadioButton installBrowserExtension clickCheckboxButton clickLink clickCheckboxButton dragElement installBrowserExtension installBrowserExtension unmutedTab installBrowserExtension dragElement clickLink installBrowserExtension attachTab deleted 8.0\n",
      "LenLog_1_1_10_5_1_5000\n",
      "paste paste printSubmitted Unmount created 0.0\n",
      " openFolder moved paste paste printSubmitted Unmount created 2.0\n",
      "LenLog_1_20_1_20_25_10_5000\n",
      "\n",
      "LenLog_1_10_1_10_5_10_500\n",
      "\n",
      "LenLog_1_1_10_5_10_500\n",
      "moved form_submit newBookmark changeField submit newTab 1.0\n",
      " openWindow moved form_submit newBookmark changeField submit newTab 2.0\n",
      "LenLog_1_20_1_10_25_5_5000\n",
      "\n",
      "LenLog_1_10_1_10_25_5_5000\n",
      "\n",
      "LenLog_1_10_1_10_5_1_5000\n",
      "modified Unmount modified modified Unmount 0.0\n",
      " modified Unmount modified modified Unmount newTab 1.0\n",
      "LenLog_1_1_10_25_5_5000\n",
      "\n",
      "LenLog_1_20_1_10_5_1_5000\n",
      "\n",
      "LenLog_1_20_1_10_5_10_500\n",
      "\n",
      "LenLog_1_10_1_60_25_1_150000.config\n",
      "\n",
      "LenLog_1_10_1_20_25_1_50000.config\n",
      "\n",
      "LenLog_1_20_1_60_25_1_150000.config\n",
      "\n",
      "LenLog_1_1_60_25_1_150000.config\n",
      "\n",
      "LenLog_1_20_1_20_25_1_50000.config\n",
      "\n",
      "LenLog_1_1_20_25_1_50000.config\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomho\\AppData\\Local\\Temp\\ipykernel_3228\\2568097475.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  filename = row[0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "folder_path = \"logs/smartRPA/percentageComparison/\"\n",
    "grundTruth_ValidationData_filename = \"Agostinelli_csv_results_500_5000_50k-150k.csv\"\n",
    "\n",
    "data = pd.read_csv(folder_path + grundTruth_ValidationData_filename, sep=\",\")\n",
    "\n",
    "# Function to add a newline after every number occurrence\n",
    "def add_newline_after_numbers(content):\n",
    "    # Remove all tabs and replace them with a single space\n",
    "    content = content.replace(\"\\t\", \" \")\n",
    "    # Split the content into lines\n",
    "    lines = content.splitlines()\n",
    "    # Remove rows that only contain 'nan' (case-insensitive)\n",
    "    cleaned_lines = [line for line in lines if not re.fullmatch(r\"(\\s*nan\\s*)+\", line, flags=re.IGNORECASE)]\n",
    "    # Rejoin the cleaned lines\n",
    "    cleaned_content = \"\\n\".join(cleaned_lines)\n",
    "    # Remove trailing occurrences of \"nan\" at the end of the content\n",
    "    cleaned_content = re.sub(r\"(\\s*nan\\s*)+$\", \"\", cleaned_content, flags=re.IGNORECASE)\n",
    "    # Add newline after every decimal number (integer or float)\n",
    "    cleaned_content = re.sub(r\"(\\b\\d+(\\.\\d+)?\\b)\", r\"\\1\\n\", cleaned_content)\n",
    "    # Strip leading and trailing whitespace\n",
    "    cleaned_content = cleaned_content.strip()\n",
    "    return cleaned_content\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    # Extract the filename from the first column\n",
    "    filename = row[0]\n",
    "    \n",
    "    # Combine the relevant row data into a string\n",
    "    content = \"\\t\".join(str(value) for value in row[2:])\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    # Add a newline after every number\n",
    "    processed_content = add_newline_after_numbers(content)\n",
    "    print(processed_content)\n",
    "\n",
    "    # Save the content to a text file with the filename\n",
    "    with open(f\"result_Agostinelli-{filename}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: pattern-LenLog_1_10_1_10_10_10_1000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_10_1_10000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_10_2-5_4000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_10_5_2000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_15_10_1500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_15_1_15000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_15_2-5_6000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_15_5_3000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_20_10_2000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_20_1_20000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_20_2-5_8000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_20_5_4000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_25_10_2500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_25_1_25000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_25_2-5_10000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_25_5_5000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_5_10_500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_5_1_5000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_5_2-5_2000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_10_5_5_1000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_10_10_1500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_10_1_15000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_10_2-5_6000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_10_5_3000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_15_10_2250.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_15_1_22500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_15_2-5_9000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_15_5_4500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_20_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_20_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_20_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_20_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_25_10_3750.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_25_1_37500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_25_2-5_15000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_25_5_7500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_5_10_750.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_5_1_7500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_5_2-5_3000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_15_5_5_1500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_10_10_2000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_10_1_20000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_10_2-5_8000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_10_5_4000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_15_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_15_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_15_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_15_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_20_10_4000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_20_1_40000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_20_2-5_16000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_20_5_8000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_25_10_5000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_25_1_50000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_25_2-5_20000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_25_5_10000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_5_10_1000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_5_1_10000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_5_2-5_4000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_20_5_5_2000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_10_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_10_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_10_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_10_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_15_10_4500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_15_1_45000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_15_2-5_18000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_15_5_9000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_20_10_6000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_20_1_60000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_20_2-5_24000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_20_5_12000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_25_10_7500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_25_1_75000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_25_2-5_30000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_25_5_15000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_5_10_1500.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_5_1_15000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_5_2-5_6000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_30_5_5_3000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_10_10_6000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_10_1_60000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_10_2-5_24000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_10_5_12000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_15_10_9000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_15_1_90000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_15_2-5_36000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_15_5_18000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_20_10_12000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_20_1_120000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_20_2-5_48000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_20_5_24000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_25_10_15000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_25_1_150000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_25_2-5_60000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_25_5_30000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_5_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_5_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_5_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_10_1_60_5_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_10_10_1000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_10_1_10000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_10_2-5_4000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_10_5_2000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_15_10_1500.txt\n",
      "Deleted: pattern-LenLog_1_1_10_15_1_15000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_15_2-5_6000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_15_5_3000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_20_10_2000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_20_1_20000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_20_2-5_8000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_20_5_4000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_25_10_2500.txt\n",
      "Deleted: pattern-LenLog_1_1_10_25_1_25000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_25_2-5_10000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_25_5_5000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_5_10_500.txt\n",
      "Deleted: pattern-LenLog_1_1_10_5_1_5000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_5_2-5_2000.txt\n",
      "Deleted: pattern-LenLog_1_1_10_5_5_1000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_10_10_1500.txt\n",
      "Deleted: pattern-LenLog_1_1_15_10_1_15000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_10_2-5_6000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_10_5_3000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_15_10_2250.txt\n",
      "Deleted: pattern-LenLog_1_1_15_15_1_22500.txt\n",
      "Deleted: pattern-LenLog_1_1_15_15_2-5_9000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_15_5_4500.txt\n",
      "Deleted: pattern-LenLog_1_1_15_20_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_20_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_20_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_20_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_25_10_3750.txt\n",
      "Deleted: pattern-LenLog_1_1_15_25_1_37500.txt\n",
      "Deleted: pattern-LenLog_1_1_15_25_2-5_15000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_25_5_7500.txt\n",
      "Deleted: pattern-LenLog_1_1_15_5_10_750.txt\n",
      "Deleted: pattern-LenLog_1_1_15_5_1_7500.txt\n",
      "Deleted: pattern-LenLog_1_1_15_5_2-5_3000.txt\n",
      "Deleted: pattern-LenLog_1_1_15_5_5_1500.txt\n",
      "Deleted: pattern-LenLog_1_1_20_10_10_2000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_10_1_20000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_10_2-5_8000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_10_5_4000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_15_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_15_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_15_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_15_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_20_10_4000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_20_1_40000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_20_2-5_16000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_20_5_8000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_25_10_5000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_25_1_50000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_25_2-5_20000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_25_5_10000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_5_10_1000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_5_1_10000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_5_2-5_4000.txt\n",
      "Deleted: pattern-LenLog_1_1_20_5_5_2000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_10_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_10_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_10_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_10_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_15_10_4500.txt\n",
      "Deleted: pattern-LenLog_1_1_30_15_1_45000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_15_2-5_18000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_15_5_9000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_20_10_6000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_20_1_60000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_20_2-5_24000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_20_5_12000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_25_10_7500.txt\n",
      "Deleted: pattern-LenLog_1_1_30_25_1_75000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_25_2-5_30000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_25_5_15000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_5_10_1500.txt\n",
      "Deleted: pattern-LenLog_1_1_30_5_1_15000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_5_2-5_6000.txt\n",
      "Deleted: pattern-LenLog_1_1_30_5_5_3000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_10_10_6000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_10_1_60000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_10_2-5_24000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_10_5_12000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_15_10_9000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_15_1_90000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_15_2-5_36000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_15_5_18000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_20_10_12000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_20_1_120000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_20_2-5_48000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_20_5_24000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_25_10_15000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_25_1_150000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_25_2-5_60000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_25_5_30000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_5_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_5_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_5_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_1_60_5_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_10_10_1000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_10_1_10000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_10_2-5_4000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_10_5_2000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_15_10_1500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_15_1_15000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_15_2-5_6000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_15_5_3000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_20_10_2000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_20_1_20000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_20_2-5_8000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_20_5_4000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_25_10_2500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_25_1_25000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_25_2-5_10000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_25_5_5000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_5_10_500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_5_1_5000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_5_2-5_2000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_10_5_5_1000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_10_10_1500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_10_1_15000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_10_2-5_6000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_10_5_3000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_15_10_2250.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_15_1_22500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_15_2-5_9000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_15_5_4500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_20_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_20_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_20_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_20_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_25_10_3750.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_25_1_37500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_25_2-5_15000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_25_5_7500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_5_10_750.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_5_1_7500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_5_2-5_3000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_15_5_5_1500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_10_10_2000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_10_1_20000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_10_2-5_8000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_10_5_4000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_15_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_15_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_15_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_15_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_20_10_4000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_20_1_40000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_20_2-5_16000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_20_5_8000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_25_10_5000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_25_1_50000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_25_2-5_20000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_25_5_10000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_5_10_1000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_5_1_10000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_5_2-5_4000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_20_5_5_2000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_10_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_10_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_10_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_10_5_6000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_15_10_4500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_15_1_45000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_15_2-5_18000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_15_5_9000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_20_10_6000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_20_1_60000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_20_2-5_24000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_20_5_12000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_25_10_7500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_25_1_75000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_25_2-5_30000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_25_5_15000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_5_10_1500.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_5_1_15000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_5_2-5_6000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_30_5_5_3000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_10_10_6000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_10_1_60000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_10_2-5_24000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_10_5_12000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_15_10_9000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_15_1_90000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_15_2-5_36000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_15_5_18000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_20_10_12000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_20_1_120000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_20_2-5_48000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_20_5_24000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_25_10_15000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_25_1_150000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_25_2-5_60000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_25_5_30000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_5_10_3000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_5_1_30000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_5_2-5_12000.txt\n",
      "Deleted: pattern-LenLog_1_20_1_60_5_5_6000.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def clean_unmatched_txt_files(folder_path):\n",
    "    \"\"\"\n",
    "    Deletes all .txt files in the specified folder that do not have a matching .csv file.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing .txt and .csv files.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Get the list of all CSV files (without extensions)\n",
    "    csv_base_names = {os.path.splitext(f)[0] for f in os.listdir(folder_path) if f.endswith('.csv')}\n",
    "\n",
    "    # Iterate over all .txt files\n",
    "    for txt_file in os.listdir(folder_path):\n",
    "        if txt_file.endswith('.txt'):\n",
    "            txt_base_name = os.path.splitext(txt_file)[0]  # Get the base name of the .txt file\n",
    "\n",
    "            # If there is no matching CSV file, delete the txt file\n",
    "            if txt_base_name not in csv_base_names:\n",
    "                os.remove(os.path.join(folder_path, txt_file))\n",
    "                print(f\"Deleted: {txt_file}\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = \"logs/smartRPA/percentageComparison/LenoComparison\"  # Replace with your folder path\n",
    "clean_unmatched_txt_files(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeSeriesData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
